\documentclass[12pt]{article}
\fontfamily{times}
\usepackage{graphicx}
\usepackage{geometry}

\usepackage{amsmath, amssymb, amsthm}
\usepackage{tikz}

\geometry{verbose,tmargin=30mm,bmargin=25mm,lmargin=25mm,rmargin=25mm}
\pagestyle{empty}

\newtheorem{theorem}[equation]{Theorem}
\newtheorem{lemma}[equation]{Lemma}
\newtheorem{proposition}[equation]{Proposition}
\newtheorem{corollary}[equation]{Corollary}
\newtheorem{definition}[equation]{Definition}
\newtheorem{example}[equation]{Example}
\newtheorem{remark}[equation]{Remark}
\newtheorem{question}[equation]{Question}
\newtheorem{notation}[equation]{Notation}
%\numberwithin{equation}{section}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\T}{\mathbb{T}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\B}{\mathfrak{B}}
\newcommand{\BB}{\mathcal{B}}
\newcommand{\M}{\mathfrak{M}}
\newcommand{\X}{\mathfrak{X}}
\newcommand{\Y}{\mathfrak{Y}}
\newcommand{\CC}{\mathcal{C}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\ZZ}{\mathcal{Z}}

%Peter's commands
\newcommand{\ex}{\mathbb {E}}
\newcommand{\pr}{\mathbb {P}}
\newcommand{\Rd}{\mathbb R^d}
\newcommand{\Rp}{\mathbb R^+}
\newcommand{\spctim}{\mathbb R^{d+1}}
\newcommand{\del}{\partial }
\newcommand{\1}{\mathbf 1}
\newcommand{\eps}{\varepsilon}

%Other commands
\newcommand{\FF}{\mathcal{F}}
\newcommand{\Law}{\mathop{\rm Law}}
\newcommand{\Cov}{\mathop{\rm Cov}}
\newcommand{\Var}{\mathop{\rm Var}}
\newcommand{\sign}{\mathop{\rm sign}}
\newcommand{\Floor}[1]{{\lfloor {#1} \rfloor}}
\newcommand{\cd}{\overset{d}{\longrightarrow}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\ppartial}[2]{\dfrac{\partial {#1}}{\partial {#2} }}
\newcommand{\cdj}{\overset{d}{\underset{J_1}{\longrightarrow}}}

\title{Threshold Exceedances and Records of Continuous Time Random Maxima}
\author{Nathan Giang \and Katharina Hees \and Peter Straka}



\begin{document}

\maketitle

\begin{abstract}
Extreme Value theory deals with the observation of extreme events which are the maxima of a sequence of observations and admits that these events occur at regular intervals in time. Recently a new theory called Continuous Time Random Maxima gets much regard which can be thought of as a generalized extreme value theory. Instead of looking at events at fixed, regular time-points, this theory assumes random waiting times between the observations. This theory provides a model for bursty events, where the waiting times between the observations are heavy tailed.\\

% This is where the abstract is placed. It should include a statement about the problem being addressed in the presentation (and paper, if submitted). Continue with a discussion of why it is important to address this problem. This may be followed by some summary information about the models and methods developed and/or used to address the problem. Conclude with a description of the key results and contributions that will be covered in the presentation (and paper).
\end{abstract}

{\bf Keywords}: CTRM; exceedances; extreme value statistics; bursts.


\setlength{\parindent}{0pt}

\section{Introduction}
Extreme Value theory deals with the observation of extreme events which are the maxima of a sequence of observations and admits that these events occur at regular intervals in time. Recently a new theory called Continuous Time Random Maxima gets much regard, which can be thought of as a generalized extreme value theory. Instead of looking at events at fixed, regular time-points, this theory assumes random waiting times between the observations.


\section{CTRMs and their scaling limits}

\subsection{CTRMs}

Let $(J,W),(J_1,W_1),(J_2,W_2), \ldots$ 
be i.i.d.\ bivariate random vectors on $\mathbb R \times (0, \infty)$. 
The components $J$ and $W$ represent an event magnitude and 
a waiting time, respectively. 
We first set up some notation: 


\begin{definition}
Write 
\begin{align}
S(t) &= \sum_{i=1}^{\lfloor t \rfloor} W_i, 
&
M(t) &= \bigvee_{i=1}^{\lfloor t \rfloor} J_i
\end{align} 
for the cumulative sum of the waiting times and the cumulative maximum of the 
magnitudes. 
The renewal process associated with $S$ is 
\begin{align} \label{eq:renewal-process}
N(t) = \max\{n \in \mathbb N: S(n) \le t\}.
\end{align}
Then the process
\begin{align}
V(t) 
= M\left( N(t) \right) 
= \bigvee_{k=1}^{N(t)} J_k, \quad t \ge 0.
\end{align}
is called a CTRM process (Continuous Time Random Maxima). Finally, the process
\begin{align}
\tilde V(t) 
= M\left( N(t) + 1 \right) 
= \bigvee_{k=1}^{N(t) + 1} J_k, \quad t \ge 0.
\end{align}
a OCTRM (Oracle Continuous Time Random Maxima).
\end{definition}

The conceptual difference between the CTRM and the OCTRM is that for the CTRM, 
the waiting time $W_k$ precedes the magnitude $J_k$, whereas for 
the OCTRM it succeeds it. In other words, for the CTRM we have 
$W_1, J_1, W_2, J_2, W_3, \ldots$ whereas for the
OCTRM, we have $J_1, W_1, J_2, W_2, J_3, \ldots$. 


\subsection{Rescaling}

\paragraph{}
Let $c > 0$ be a scaling parameter, and let 
$a(c), b(c)$ and $d(c)$ be deterministic scaling functions,
defining rescaled waiting times and magnitudes as follows: 
\begin{align}
J^{(c)} &\stackrel{d}{=} \frac{J - d(c)}{a(c)}, 
& 
W^{(c)} &\stackrel{d}{=} \frac{W}{b(c)}
\end{align}
where $\stackrel{d}{=}$ denotes equality in distribution. 
Starting from $W^{(c)}$ and $J^{(c)}$ rather than $W$ and $J$, we thus define rescaled 
versions $S^{(c)}, M^{(c)}, N^{(c)}, V^{(c)}$ and $\tilde V^{(c)}$ of the 
stochastic processes introduced above. 

\paragraph{}
Throughout, we assume that the distribution of $J$ is continuous. 
It is then well-known in extreme value theory that there exist $a(c)$ and $d(c)$
such that 
$M^{(c)}(c)$ converges weakly to a random variable $A$ with 
Generalized Extreme Value (GEV) distribution. 
\begin{align}
M^{(c)}(c) \stackrel{d}{\to} A,
\quad \PP(A \le z) = G(z) = \exp\left(-[1+\xi z]^{-1/\xi}\right). \label{Mises}
\end{align}
Equation \eqref{Mises} is the so-called van-Mises representation for 
Extreme Value distributions. 
It comprises the Fr\'echet ($\xi>0$), Weibull ($\xi<0$),
and Gumbel ($\xi = 0$) distributional families. 
We write ${\rm GEV}(\xi, \mu, \sigma)$ for the probability 
distribution of the random variable $\sigma A + \mu$. 

The extremal limit theorem allows for an extension to a functional
limit: assume that the norming sequences $a(n)$ and $d(n)$ are as 
in Theorem~\ref{th:GP}. Then 
\begin{align*}
M^{(c)}(\lfloor ct \rfloor)
\stackrel{d}{\to} A(t),
\quad c \to \infty.
\end{align*}
Convergence is in Skorokhod's $J_1$ topology, and the limit
process $A(t)$ is an \emph{extremal process}, with
finite-dimensional distributions given by
\begin{align*}
\PP(A(t_i)\leq x_i,1\leq i \leq d) 
= F_A(\wedge_{i=1}^d x_i)^{t_1} 
F_A(\wedge_{i=2}^d x_i)^{t_2-t_1}
\ldots F_A(x_d)^{t_d-t_{d-1}},
\end{align*}
with $F_A(x)$ being a GEV distribution.

In this text, we assume that the waiting times $W^{(c)}_k$ have a tail
parameter $\beta \in (0,1)$, i.e. 
$\PP(W^{(c)} > t) \sim L(t) t^{-\beta}$ as $t \uparrow \infty$ 
for some slowly varying function $L(t)$.\footnote{
We write $f(t) \sim g(t)$ if their quotient converges to $1$.
}
The $W^{(c)}_k$ are then said to lie in the 
domain of attraction of a stable law, meaning that 
\begin{align}\label{eq:sclt}
S^{(n)}(n) \overset{d}{\longrightarrow} D, 
\quad n \to \infty
\end{align}
exists, for some regularly varying $b(c)$ at $\infty$ with parameter $1/\beta$;
we write $b(c) \in {\rm RV}_\infty(1/\beta)$.
The limit $D$ is then a positively skewed stable random variable, with
$\E[\exp(-sD)] = \exp(-s^\beta)$.
As for the maximum, the following functional limit theorem holds for the sum:
\begin{align}
S^{(c)}(\Floor{ct}) \overset{d}{\longrightarrow} D(t), 
\quad c \to \infty
\end{align}
with convergence in the Skorokhod $J_1$ topology.
The limit $D(t)$ is a stable subordinator, i.e.\ an increasing
L\'evy process with Laplace transform $\exp(-t s^\beta)$.\\ 
It is well known (see e.g.\ \cite{limitCTRW}) that the renewal
process then satisfies the functional limit
\begin{align}
N(ct)/\tilde b(c) \cd E(t) = \inf\{r: D(r) > t\}, 
\quad c \to \infty
\end{align}
for a scaling function $\tilde b(c)$ which is 
asymptotically inverse to $b(c)$, in the sense
of \cite[p.20]{seneta}: 
\begin{align}\label{eq:tildeb}
b(\tilde b(c)) \sim c \sim \tilde b(b(c)).
\end{align}
Note that $\tilde b \in {\rm RV}_\infty(\beta)$ 
\cite{limitCTRW}.
The limit process $E(t)$ is called the \emph{inverse} stable
subordinator \cite{invSubord}.
Was hier noch alles rein muss: BUT KEEP IT SHORT
\begin{itemize} 
\item extreme value distribution
\item convergence of M(n)
\item Überleiten zu CTRM, via heavy-tailed waiting times, etc.
\item $J_1$ convergence definition
\item $J_1$ convergence of M(nt)
\item defintion of extremal processes 
\end{itemize}



\section{Scaling limits of threshold event time and magnitude}

\begin{definition}
Let $\ell \in (x_L, x_R)$ be a threshold, and write 
$$
p(c) := 1-F_J^{(c)}(\ell) = 1-F_J(a(c) \ell + d(c))
$$
for the probability of a threshold crossing at scale $c$. 
Write 
$$
N(p(c)) := \min\{n: J^{(c)}_n > \ell\} \sim {\rm Geo}(p(c))
$$
for the index of the first threshold 
exceedance, and call
\begin{align*}
  Y^{(c)}(\ell) := J^{(c)}_{N(p(c))}
\end{align*}
the \textbf{threshold event magnitude}. The random variables 
\begin{align}
  T^{(c)}(\ell) = \sum_{n=1}^{N(p(c))} W^{(c)}_k \quad \text{resp.} \quad 
  T'^{(c)}(\ell) = \sum_{n=1}^{N(p(c))-1} W^{(c)}_k
\end{align}
are then called the \textbf{threshold event time} for the CTRM resp.\ the 
OCTRM. 
\end{definition}

\begin{proposition}[don't know if we'll need this]\label{lem:independence}
Let $\ell \in (x_L, x_R)$. 
\begin{enumerate}
  \item 
  $T'(\ell)$ and $Y(\ell)$ are independent. 
  \item
  $Y(\ell)$ has the same distribution as $J$ conditional on $J > \ell$. 
\end{enumerate}
\end{proposition}

\begin{proof}
1. follows from the $\sigma$-algebras generated by 
$(W_1, J_1), \ldots, (W_{N(p)-1}, J_{N(p)-1})$ and 
$(W_{N(p)}, J_{N(p)})$ being independent. 
2. follows from the i.i.d.\ property of the sequence $J_k$. 
\end{proof}

\begin{theorem}
  At scale $c$, define the stochastic processes 
  \begin{align*}
    Y^{(c)} &:= \{Y^{(c)}(x)\}_{x \in D}, 
    & T^{(c)} &:= \{T^{(c)}(x)\}_{x \in D}, 
    & T'^{(c)} &:= \{T'^{(c)}(x)\}_{x \in D}
  \end{align*}
  where $D$ is the support of the GEV distribution which attracts 
  $J$. Then in the Skorokhod $M_1$-topology, the following limits exist:
  \begin{enumerate}
    \item 
    $\lim \limits_{c \to \infty} Y^{(c)} = Y := \{A \circ A^{-1}(x)\}_{x \in D}$
    \item
    $\lim \limits_{c \to \infty} T^{(c)} = T := \{D \circ A^{-1}(x)\}_{x \in D}$
    \item
    $\lim \limits_{c \to \infty} T'^{(c)} = T' 
    := \{(D_- \circ A^{-1}_-)_+(x)\}_{x \in D}$
  \end{enumerate}
\end{theorem}

\begin{proof}
  Kathi?
\end{proof}

It is well-known, that the excess function of $J$ is asymptotically Generalised Pareto distributed, i.e.
\begin{align*}
\PP(J_1 - \ell > y | J_1 > \ell) 
\approx (1+ \xi y / \tilde \sigma)^{-1/\xi} \rightarrow 1 - H(y) \text{ as } \ell \uparrow x_R,
\end{align*}
where $\tilde \sigma :=\sigma + \xi(\ell-\mu)$, $y>0$ and $1+\xi y/\tilde \sigma >0$. A distribution with CDF $H(y)$ is said to be from the \textbf{Generalised Pareto family}
$GP(\xi,\bar \sigma)$.\\  

\begin{theorem}(Verteilungskonvergenz der exceedance time)
For fixed $l>0$
\begin{align}
b(c) T(cl) \Rightarrow H(l) \text{ as } c \rightarrow \infty
\end{align} 
Where the CDF of $H(l)$ is given by
\begin{align*}
XX
\end{align*}
\end{theorem}

We can even show that the exceedance time process $(T_l)_{l \in \N}$ in converges to the inverse of CTRM resp. OCTRM limit in the $M_1$-topology.


\begin{theorem}(M1 convergence of the exceedance)
We have 
\begin{align*}
(T(cl))_{l \in [x_L,x_R]}  \rightarrow (D(A^{-1}(l)))_{l \in [x_L,x_R]} 
\end{align*}
\end{theorem}
Since the inverse function on XX is not continuous in Skorokhod's $J_1$ topology, we only get the convergence in the $M_1$ topology.\\
In XX and before in XX without noting it, it was shown, that in the uncoupled case the exceedance time is asymptomatically Mittag-Leffler distributed. This surprisingly holds in the coupled case as well. For$\beta \in (0,1)$, a standard Mittag-Leffler 
random variable $Y$ is positive with Laplace transform
$\E[\exp(-s Y)] = 1/(1+s^\beta)$. For $\sigma > 0$, we then write 
${\rm ML}(\beta, \sigma)$ for the distribution of $\sigma Y$. \\


\begin{theorem}(Asymptotic distribution of the exceedance (magnitudes))
We have 
\begin{align*}
(X(cl))_{l \in (0,1)} \rightarrow (A(A^{-1}(l)))_{l \in (0,1)} - l
\end{align*}
\end{theorem}

To proof this, we will first proof the following lemma.

\begin{lemma} 
Assume $(x_n)_{n \in \N} \subset \D$ and we have
\begin{align*}
x_n \rightarrow x  \text{ and }  x_n^{-1} \rightarrow x^{-1}. 
\end{align*}
Then it follows, that
\begin{align*}
x_n \circ x_n^{-1} \rightarrow x \circ x^{-1}.
\end{align*}
\end{lemma}


\section{Joint distribution of threshold event and threshold crossing time}

Define the potential measure, or expected occupation time, of the bivariate 
Markov process $(A(u),D(u))$:

\begin{align*}
U(B) = \ex \left[ \int_0^\infty \mathbf 1\{ (A_u, D_u) \in B\}\,du \right]
\end{align*}

Define the bivariate tail function $\overline \nu(x,t)$ via 

\begin{align}
\overline \nu(x,t) = \lim_{c \to \infty} c \pr [J^{(c)} > x, W^{(c)} > t]
\end{align}


\begin{theorem}
\begin{align}
\pr [T(\ell) > t, Y(\ell) > y]
= \iint\limits_{x \le \ell, t' \in [0,t)} \overline \nu(y, t - t') U(dx, dt')
\end{align}
\end{theorem}


\section{Semi-Markov property of Record process}

\begin{proposition}
The CTRM and OCTRM processes are Semi-Markov processes: 
Let $\mathcal R = \{0\} \cup \{\sum_{k=1}^n W_k, n \in \mathbb N\}$ denote the set of renewal times, and let 
\begin{align*}
Z(t) = t - \sup((-\infty, t] \cap \mathcal R)
\end{align*}
be the \emph{age}, i.e.\ the time passed since the last renewal. Then the bivariate processes 
\begin{align*}
(V(t), Z(t)), \quad (\tilde V(t), Z(t)), \quad t \ge 0,
\end{align*}
are Markov processes with respect to their natural filtrations $\mathcal F_t = \sigma(V(s): s \le t)$ and $\tilde{\mathcal F}_t = \sigma(\tilde V(s): s \le t)$. 
\end{proposition}

The proof is deferred to Section \ref{sec:records}.

In XX it was shown that the CTRM $V(t) = M(N(t)$ and the OCTRM $\tilde V(t)$ have the following functional scaling limit in the Skorokhod $J_1$ topology: 
\begin{align*}
[V(ct) - d(\tilde b(c))] / a(\tilde b(c)) \stackrel{d}{\to} 
A(E(t)), \quad c \to \infty.
\end{align*}
Hence its scaling limit results from the time-change .....
We set $M(0) = x_L$, and $\max\{\} = 0$. 



\section{Point process characterization of records}
\label{sec:records}

%It is self-similar with exponent $\beta$
%\cite{limitCTRW}, non-decreasing, and the (regenerative, random) set 
%$\mathcal R$ of its points of increase is a fractal with dimension $\beta$ 
%\cite{Bertoin04}.
%$E(t)$ is hence a model for time series with intermittent, `bursty'
%behaviour, for the following reasons:
%\begin{itemize}
%\item
%If $t \in \mathcal R$, for any $\epsilon > 0$ the interval
%$(t, t+ \epsilon)$ almost surely contains uncountably many other points of $\mathcal R$ (a ``bursty'' period)
%\item 
%If $t \notin \mathcal R$, then there is $\epsilon > 0$ such that
%$(t, t+ \epsilon)$ contains no other 
%\item [ii)]
%$\mathcal R$ has Lebesgue measure $0$, and hence $E(t)$ is
%constant at any ``randomly'' chosen time $t$. 
%\end{itemize}
%Having only two parameters ($\alpha \in (0,1)$ and a scale parameter)
%the inverse stable subordinator hence models scaling limits of heavy-tailed 
%waiting times parsimoniously.

The book \cite[Chapter 4]{resnick2013extreme} nicely characterizes the structure of records of extreme value processes. Record values and inter-record times follow a bivariate Poisson Point Process, whose intensity measure depends on the underlying distribution of event magnitudes. We generalize these results for max-renewal processes with regularly varying waiting times with infinite mean. 

A \textit{record time} $L$ for a CTRM $V(t)$ is defined by 
\begin{align*}
V(L) > V(t), \quad t < L.
\end{align*}
Paths of CTRMs are piecewise constant, non-decreasing and right-continuous, hence the above is well-defined and the $L$'s form an increasing sequence $\{L_n\}$. The \textit{record values} are then defined as $V(L_n)$. Clearly, the $L_n$ lie in the set $\mathcal R$ of renewal times, i.e.\ $L_n = W_1 + \ldots + W_{\tau(n)}$ for some integer $\tau(n)$. 

Given a record at $L_n$, the next record time $L_{n+1}$ occurs with the first event magnitude $J_k, k \ge \tau(n)$, which is larger than $V(L_n)$. As the $J_k$ are i.i.d., $\tau(n+1) - \tau(n)$ must be geometrically distributed, with parameter $p = 1 - F_J(V(L_n))$, and hence 
\begin{align} \label{eq:geometric-sum}
L_{n+1} - L_n \stackrel{d}{=} \sum_{k=1}^{N(p)} W_k
\end{align}
where $N(p) \sim {\rm Geom}(p)$, independent of the $W_k$. 

The record values $V(L_n)$ form a Markov chain (see e.g.\ \cite{resnick2013extreme}), and moreover we may characterize the record structure of CTRMs as follows: 

\begin{proposition}
\begin{enumerate}
\item
$\{V(L_n), n \ge 1\}$ is a Markov chain with stationary transition probabilities satisfying
\begin{align*}
\Pi(x, (y,\infty)) = 
\begin{cases}
(1-F(y)) / (1-F(x)), & y > x
\\
1, & y \le x
\end{cases}
\end{align*}
\item
$\{V(L_n), n \ge 1\}$ are the points of a Poisson random measure on $(x_l, x_0)$ with intensity measure
\begin{align*}
R(a,b] = R(b) - R(a)
\end{align*}
where $R(t) = -\log(1-F(t))$. 
\item
If $F_J$ is continuous, $\{V(L_n), L_{n+1} - L_n, n \ge 1\}$ are the points of a bivariate Poisson random measure on
$(x_l, x_0) \times (0,\infty)$ with intensity measure
\begin{align*}
\mu^*(dx, dy) = R(dx) F_W^{*N(1-F_J(x))}(dy),
\end{align*}
where $F_W^{*N(1-F_J(x))}(dy)$ is the convolution of the measure $F_W(dy)$ with itself, taken an independent geometric number of times, with success probability $p = 1-F_J(x)$.
\end{enumerate}
\end{proposition}

\begin{proof}
Parts 1 \& 2 are proven in 
\cite[Proposition 4.1 (i) \& (iii)]{resnick2013extreme}.
Part 3 follows from \cite[Proposition 3.8]{resnick2013extreme}, 
applied to the transition function $K(x,dy)$ corresponding to the law \eqref{eq:geometric-sum} of $L_{n+1} - L_n = y$, conditional on $V(L_n) = x$. 
\end{proof}




\section{Governing Equations of CTRM limits}




%\section{Conclusion}
\section{Conclusion}


{\bf Acknowledgements.} P. Straka was supported by the Australian Research Council’s Discovery Early Career Research Award DE160101147.


\bibliographystyle{alpha}
\bibliography{CTRMstats}



\end{document}
