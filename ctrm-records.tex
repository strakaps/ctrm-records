\documentclass[12pt, a4paper]{article}
\fontfamily{times}
\usepackage{graphicx}
\usepackage{geometry}

\usepackage{amsmath, amssymb, amsthm}
\usepackage{tikz}

\geometry{verbose,tmargin=30mm,bmargin=25mm,lmargin=25mm,rmargin=25mm}
\pagestyle{empty}

\newtheorem{theorem}[equation]{Theorem}
\newtheorem{lemma}[equation]{Lemma}
\newtheorem{proposition}[equation]{Proposition}
\newtheorem{corollary}[equation]{Corollary}
\newtheorem{definition}[equation]{Definition}
\newtheorem{example}[equation]{Example}
\newtheorem{remark}[equation]{Remark}
\newtheorem{question}[equation]{Question}
\newtheorem{notation}[equation]{Notation}
%\numberwithin{equation}{section}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\T}{\mathbb{T}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\B}{\mathfrak{B}}
\newcommand{\BB}{\mathcal{B}}
\newcommand{\M}{\mathfrak{M}}
\newcommand{\X}{\mathfrak{X}}
\newcommand{\Y}{\mathfrak{Y}}
\newcommand{\CC}{\mathcal{C}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\ZZ}{\mathcal{Z}}

%Peter's commands
\newcommand{\ex}{\mathbb {E}}
\newcommand{\pr}{\mathbb {P}}
\newcommand{\Rd}{\mathbb R^d}
\newcommand{\Rp}{\mathbb R^+}
\newcommand{\spctim}{\mathbb R^{d+1}}
\newcommand{\del}{\partial }
\newcommand{\1}{\mathbf 1}
\newcommand{\eps}{\varepsilon}

%Other commands
\newcommand{\FF}{\mathcal{F}}
\newcommand{\Law}{\mathop{\rm Law}}
\newcommand{\Cov}{\mathop{\rm Cov}}
\newcommand{\Var}{\mathop{\rm Var}}
\newcommand{\sign}{\mathop{\rm sign}}
\newcommand{\Floor}[1]{{\lfloor {#1} \rfloor}}
\newcommand{\cd}{\overset{d}{\longrightarrow}}
\newcommand{\cJ}{\overset{J_1}{\longrightarrow}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\ppartial}[2]{\dfrac{\partial {#1}}{\partial {#2} }}
\newcommand{\cdj}{\overset{d}{\underset{J_1}{\longrightarrow}}}

\title{Threshold Exceedances and Records of Continuous Time Random Maxima}
\author{Nathan Giang \and Katharina Hees \and Peter Straka}



\begin{document}

\maketitle

\begin{abstract}
Extreme Value theory deals with the observation of extreme events which are the maxima of a sequence of observations and admits that these events occur at regular intervals in time. Recently a new theory called Continuous Time Random Maxima gets much regard which can be thought of as a generalized extreme value theory. Instead of looking at events at fixed, regular time-points, this theory assumes random waiting times between the observations. This theory provides a model for bursty events, where the waiting times between the observations are heavy tailed.\\

% This is where the abstract is placed. It should include a statement about the problem being addressed in the presentation (and paper, if submitted). Continue with a discussion of why it is important to address this problem. This may be followed by some summary information about the models and methods developed and/or used to address the problem. Conclude with a description of the key results and contributions that will be covered in the presentation (and paper).
\end{abstract}

{\bf Keywords}: CTRM; exceedances; extreme value statistics; bursts.


\setlength{\parindent}{0pt}

\section{Introduction}
Extreme Value theory deals with the observation of extreme events which are the maxima of a sequence of observations and admits that these events occur at regular intervals in time. Recently a new theory called Continuous Time Random Maxima gets much regard, which can be thought of as a generalized extreme value theory. Instead of looking at events at fixed, regular time-points, this theory assumes random waiting times between the observations.


\section{CTRMs and their scaling limits}

\subsection{CTRMs}

Let $(J,W),(J_1,W_1),(J_2,W_2), \ldots$ 
be i.i.d.\ bivariate random vectors on $\mathbb R \times (0, \infty)$. 
The components $J$ and $W$ represent an event magnitude and 
a waiting time, respectively. 
We first set up some notation: 


\begin{definition}
We write $S^{(c)}(n)$ and $M^{(c)}(n)$ for the \textbf{cumulative sum of the waiting times} $(W^{(c)})_{i \in \N}$ and the \textbf{cumulative maximum of the magnitudes} $(J^{(c)})_{i \in \N}$, more precisely 
\begin{align}
S(t) &= \sum_{i=1}^{\lfloor t \rfloor} W_i, 
&
M(t) &= \bigvee_{i=1}^{\lfloor t \rfloor} J_i
\end{align} 
for the cumulative sum of the waiting times and the cumulative maximum of the 
magnitudes. 
The renewal process associated with $S$ is 
\begin{align} \label{eq:renewal-process}
N(t) = \max\{n \in \mathbb N: S(n) \le t\}.
\end{align}
Finally the process
\begin{align}
V(t) 
= M\left( N(t) \right) 
= \bigvee_{k=1}^{N(t)} J_k, \quad t \ge 0.
\end{align}
is called a \textbf{CTRM process (Continuous Time Random Maxima)} and moreover the process
\begin{align}
\tilde V(t) 
= M\left( N(t) + 1 \right) 
= \bigvee_{k=1}^{N(t) + 1} J_k, \quad t \ge 0.
\end{align}
an \textbf{OCTRM (Oracle Continuous Time Random Maxima)}
.
\end{definition}

The conceptual difference between the CTRM and the OCTRM is that for the CTRM, 
the waiting time $W_k$ precedes the magnitude $J_k$, whereas for 
the OCTRM it succeeds it. In other words, for the CTRM we have 
$W_1, J_1, W_2, J_2, W_3, \ldots$ whereas for the
OCTRM, we have $J_1, W_1, J_2, W_2, J_3, \ldots$. 


\subsection{Rescaling}

\paragraph{}
Let $c > 0$ be a scaling parameter, and let 
$a(c), b(c)$ and $d(c)$ be deterministic scaling functions,
defining rescaled waiting times and magnitudes as follows: 
\begin{align}
J^{(c)} &\stackrel{d}{=} \frac{J - d(c)}{a(c)}, 
& 
W^{(c)} &\stackrel{d}{=} \frac{W}{b(c)}
\end{align}
where $\stackrel{d}{=}$ denotes equality in distribution. 
Starting from $W^{(c)}$ and $J^{(c)}$ rather than $W$ and $J$, we thus define rescaled 
versions $S^{(c)}, M^{(c)}, N^{(c)}, V^{(c)}$ and $\tilde V^{(c)}$ of the 
stochastic processes introduced above. 

\paragraph{}
Throughout, we assume that the distribution of $J$ is continuous. 
It is then well-known in extreme value theory that there exist $a(c)$ and $d(c)$
such that as $c \to \infty$,
$M^{(c)}(c)$ converges weakly to a random variable $A$ with a
Generalized Extreme Value (GEV) distribution: 
\begin{align}
M^{(c)}(c) \stackrel{d}{\to} A,
\quad \PP(A \le z) = G(z) = \exp\left(-[1+\xi z]^{-1/\xi}\right), 
\quad 1 + \xi z > 0. \label{Mises}
\end{align}
Equation \eqref{Mises} is the so-called van-Mises representation for 
Extreme Value distributions. 
It comprises the Fr\'echet ($\xi>0$), Weibull ($\xi<0$),
and Gumbel ($\xi = 0$) distributional families. 
We write ${\rm GEV}(\xi, \mu, \sigma)$ for the probability 
distribution of the random variable $\sigma A + \mu$. 

\paragraph{}
The extremal limit theorem allows for an extension to a functional
limit: 
\begin{align} \label{eq:extremal-limit}
M^{(c)}(ct)
\stackrel{d}{\to} A(t),
\quad c \to \infty.
\end{align}
The convergence is in $J_1$-topology, the strongest of the topologies defined by Skorokhod in XX and which is sometimes also called Skorokhod topology. The limit process $A(t)$ is an F-extremal process, with finite-dimensional distributions given by
\begin{align*}
\PP(A(t_i)\leq x_i,1\leq i \leq d) = G(\wedge_{i=1}^d x_i)^{t_1}  G(\wedge_{i=2}^d x_i)^{t_2-t_1} \cdot \ldots \cdot G(x_d)^{t_d-t_{d-1}}.
\end{align*}

\paragraph{}
We study the case where the waiting times $W$ have a heavy tail with
parameter $\beta \in (0,1)$, i.e.\ 
$$
\PP(W > t) \sim L(t) t^{-\beta}, \quad t \uparrow \infty
$$ 
for some slowly varying function $L(t)$.\footnote{
We write $f(t) \sim g(t)$ if their quotient converges to $1$.
}
The $W_k$ are then said to lie in the 
domain of attraction of a stable law, meaning that 
\begin{align}\label{eq:sclt}
S^{(c)}(c) \overset{d}{\longrightarrow} D, 
\quad c \to \infty
\end{align}
exists, for some $b(c)$ which varies regularly at $\infty$ with exponent 
$1/\beta$. 
The limit $D$ is then a positively skewed stable random variable, defined via
its Laplace transform $\E[\exp(-sD)] = \exp(-s^\beta)$.
As for the maximum, the following functional limit theorem holds for the sum:
\begin{align}
S^{(c)}(ct) \overset{d}{\longrightarrow} D(t), 
\quad c \to \infty
\end{align}
with convergence in the Skorokhod $J_1$ topology.
The limit $D(t)$ is a stable subordinator, i.e.\ an increasing
L\'evy process with Laplace transform $\exp(-t s^\beta)$.

\paragraph{}
It is well known (see e.g.\ \cite{limitCTRW}) that the renewal
process then satisfies the functional limit
\begin{align}
N^{(c)}(t)/\tilde b(c) \cd E(t) = \inf\{r: D(r) > t\}, 
\quad c \to \infty
\end{align}
for a scaling function $\tilde b(c)$ which is asymptotically inverse to $b(c)$, in the sense of \cite[p.20]{seneta}: 
\begin{align}\label{eq:tildeb}
b(\tilde b(c)) \sim c \sim \tilde b(b(c)).
\end{align}
Note that $\tilde b \in {\rm RV}_\infty(\beta)$ 
\cite{limitCTRW}.
The limit process $E(t)$ is called the \emph{inverse} stable
subordinator \cite{invSubord}.

\paragraph{}
Finally, we can give the functional limit of the CTRM and OCTRM processes. 
For the OCTRM, we have 
\begin{align}
  \lim \limits_{c \to \infty} \tilde V^{(c)}(t) = \tilde V(t) 
  := A \circ E(t),
\end{align}
where $\circ$ denotes stochastic process composition. For the CTRM, we have 
\begin{align}
\lim \limits_{c \to \infty} V^{(c)}(t) = V(t) 
:= (A_- \circ E)_+(t),
\end{align}
where $A_-$ denotes the version of $A$ with left-continuous sample paths, and 
where the composition is re-cast to be right-continuous; see \cite{Hees17}. 


\section{Threshold events: time and magnitude}

\begin{definition}
Write $\mathbf U$ for the interior of the support of the GEV distribution from 
\eqref{Mises}. 
Let $u \in \mathbf U$ be a threshold, and write 
$
\tau^{(c)}(u) := \min\{n: J^{(c)}_n > u\}
$
for the index of the first threshold exceedance. 
Then
\begin{align*}
  Y^{(c)}(u) := J^{(c)}_{\tau^{(c)}(u)}
\end{align*}
is called the \textbf{threshold event magnitude}. The random variables 
\begin{align}
  T^{(c)}(u) = \sum_{n=1}^{\tau^{(c)}(u)} W^{(c)}_n \quad \text{resp.} \quad 
  T'^{(c)}(u) = \sum_{n=1}^{\tau^{(c)}(u)-1} W^{(c)}_n
\end{align}
are then called the \textbf{threshold event time} for the CTRM resp.\ the 
OCTRM. 
\end{definition}

(Note that $J^{(c)} \le u$ iff $J \le a(c) u + d(u)$, and that 
$a(c) u + d(u) \uparrow x_R$ as $c \to \infty$.) 

\begin{theorem}
  At scale $c$, define the stochastic processes 
  \begin{align*}
    Y^{(c)} &:= \{Y^{(c)}(u)\}_{u \in \mathbf U}, 
    & T^{(c)} &:= \{T^{(c)}(u)\}_{u \in \mathbf U}, 
    & T'^{(c)} &:= \{T'^{(c)}(u)\}_{u \in \mathbf U}.
  \end{align*}
Then in the Skorokhod $M_1$-topology, the following limits exist:
  \begin{enumerate}
    \item 
    $\lim \limits_{c \to \infty} Y^{(c)} = Y := \{A \circ A^{-1}(u)\}_{u \in \mathbf U}$
    \item
    $\lim \limits_{c \to \infty} T^{(c)} = T := \{D \circ A^{-1}(u)\}_{u \in \mathbf U}$
    \item
    $\lim \limits_{c \to \infty} T'^{(c)} = T' 
    := \{(D_- \circ A^{-1}_-)_+(u)\}_{u \in \mathbf U}$
  \end{enumerate}
\end{theorem}

\begin{proof}
  Kathi?
\end{proof}





\section{Joint distribution of threshold event and threshold crossing time}

Define the potential measure, or expected occupation time, of the bivariate 
Markov process $(A(u),D(u))$:

\begin{align*}
U(B) = \ex \left[ \int_0^\infty \mathbf 1\{ (A_u, D_u) \in B\}\,du \right]
\end{align*}

Define the bivariate tail function $\overline \nu(x,t)$ via 

\begin{align}
\overline \nu(x,t) = \lim_{c \to \infty} c \pr [J^{(c)} > x, W^{(c)} > t]
\end{align}


\begin{theorem}
\begin{align}
\pr [T(u) > t, Y(u) > y]
= \iint\limits_{x \le u, t' \in [0,t)} \overline \nu(y, t - t') U(dx, dt')
\end{align}
\end{theorem}


\section{Semi-Markov property of CTRMs}
\label{sec:records}

\paragraph{}
The maximal process $M = \{M(n)\}_{n\in \mathbb N}$ 
and the extremal process $A = \{A(t)\}_{t > 0}$
are well understood, see e.g. \cite[Chapter 4]{resnick2013extreme}. 
Both are Markov processes with piecewise constant non-decreasing sample paths, 
in discrete time ($M$) resp. continuous time ($A$). 
The sample paths of $A$ are right-continuous. 
The jump times (i.e. points of increase) $\tau_n$ are called \emph{record times}, 
and their values at the record times are called \emph{records}. 
At a record $x$, the holding time for $M$ follows a ${\rm Geo}(1-F(x))$ distribution, 
where $F(x)$ is the cumulative distribution of magnitudes. 
For $A$, the holding time is ${\rm Exp}(-\log G(x))$ distributed, where $G(x)$
is the underlying GEV distribution.\footnote{In general, extremal processes can 
be defined using any continuous distribution $F$, but the limit 
\eqref{eq:extremal-limit} results in the GEV distribution $G$.}
The probability distribution of the next record $y$ is simply given by 
\begin{align} \label{eq:record-chain-1}
  \PP[M(\tau_{n+1}) > y | M(\tau_n) = x] &= 1 \wedge \frac{1-F(y)}{1-F(x)}, 
  \\
  \label{eq:record-chain-2}
  \PP[A(\tau_{n+1}) > y | A(\tau_n) = x] &= 1 \wedge \frac{-\log G(y)}{-\log G(x)}.
\end{align}
Finally, even more can be said about the structure of records: 
the set of all records is a Poisson Point process (PPP) with
mean measure $R(dx) = d(-\log (1-F(x)))$ for $M$ and 
$d(-\log (-\log G(x)))$ for $A$.
In the special case $F(x) = 1-e^{-x}$ resp. where $G(x)$ is the Gumbel distribution 
($\xi = 0$), the mean measure is Lebesgue measure (on $(0, \infty)$ resp. $\mathbb R$).


\paragraph{}
Paths of the CTRM process $V^{(c)}$ and the CTRM limit process $V$
result from time changes of $M^{(c)}$ and $A$. 
Hence the set of points traversed by them, i.e. the set of records, 
follows the same probability law, and the only difference lies in the 
distribution of the holding times. 

\begin{proposition} \label{prop:semi-markov}
  The CTRM process $V^{(c)}$, the OCTRM process $\tilde V^{(c)}$ and their 
  scaling limits $V$ resp. $\tilde V$, are all Semi-Markov processes. 
  Their holding times at a record $x$ are, respectively, 
  \begin{align}
    T^{(c)}(x), \quad W^{(c)}(x) + T'^{(c)}(x), \quad T(x), \quad W(x) + T'(x),
  \end{align}
  where $W^{(c)}(x)$ resp. $W(x)$ is an independent random variable with density 
  \begin{align} \label{eq:conditional-W}
    t \mapsto \frac{\nu^{(c)}(x,t)}{\int \limits_{[0,\infty)} \nu^{(c)}(x,t')\,dt'}
    \quad \text{ resp. } \quad 
    t \mapsto \frac{\nu(x,t)}{\int \limits_{[0,\infty)} \nu(x,t')\,dt'}
  \end{align}
\end{proposition}

\begin{proof}
  As mentioned above, the sequence of records is a Markov chain, and it only 
remains to show that the holding time $\tau_{n+1} - \tau_n$ only depends on 
the current record $V(\tau_n)$, that is, 
\begin{align}
  \PP[\tau_{n+1} - \tau_n | \tau_1, \ldots, \tau_n, V(\tau_1), \ldots V(\tau_n)]
  = \PP[\tau_{n+1} - \tau_n | V(\tau_n)].
\end{align}

For the CTRM, if $x = V^{(c)}(\tau_n) = J^{(c)}_k$ is a record, then the record time 
is $\tau_n = W^{(c)}_1 + \ldots + W^{(c)}_k$.
It marks the beginning of the waiting time $W^{(c)}_{k + 1}$, a magnitude
$J^{(c)}_{k+1}$, and so on.
Hence the CTRM is renewed at $\tau_n$, and the time until 
the next record $y = V^{(c)}(\tau_{n+1})$, i.e. the holding time at $x$, is
equal in distribution to $T^{(c)}(x)$.

For the OCTRM, and a record as above, 
the record time is $\tau_n = W^{(c)}_1 + \ldots + W^{(c)}_{k-1}$.
This shows that the OCTRM is renewed only after the following waiting time $W^{(c)}_k$. 
The holding time is hence equal in distribution to 
$W(x) + T'^{(c)}(x)$, 
where $W(x)$ has the density \eqref{eq:conditional-W}

For the CTRM limit, let $\tau$ be a record time, i.e. $V(\tau) = x$ and  
$V(t) < x$ if $t < \tau$. 
Then for any $\eps > 0$, 
$\tau = \inf\{t: V(t) > x-\eps\} = \inf\{t: (A_- \circ E)_+(t) > x-\eps\}
= \inf\{t: A_- \circ E(t) > x-\eps\}$.
By construction, $E$ must be right-increasing at $\tau$, 
i.e. $E(t) > E(\tau)$ if $t > \tau$. If it wasn't, we would have
$V(\tau) = A_- \circ E(\tau)$, which is the value of $A$ just before it reaches 
$x$, in cotradition to $V(\tau) = x$.
Thus $\tau = D(u)$ for some $u \ge 0$, which means that $\tau$ is a renewal point
(compare \cite{Bertoin04}). 
The time until an exceedance of $x$ is hence just $T(x)$. 

For the OCTRM limit, let $x$ be a record and $\tau$ a record time, i.e. 
$\tilde V(\tau) = A \circ E(t) = x$ and $\tilde V(\tau - \eps) < x$. 
Then $E(\tau)$ is a jump time of $A$, i.e. $u = E(\tau)$ marks the first occurrence 
of an event $J_u \ge x$. 
Since we do not assume the uncoupled
case, $D$ may also have a jump $W_u > 0$ at $u$. 
This means that $E$ is constant on the interval $[\tau, \tau + W_u]$, 
and the next renewal time after $\tau$ is $\tau + W_u$.
Given the event $J_u = x$, the distribution of $W_u | J_u = x$ 
has the density \eqref{eq:conditional-W}.
Then the time until the next record $y$, i.e. the holding time at $x$, is 
equal in distribution to $W(x) + T'(x)$. 
\end{proof}


\begin{theorem}
Suppose $F_J$ is continuous, and let 
\begin{align}
  R(dx) = d(-\log(1-F(x))), \quad S(dx) = d(-\log(-\log G(x))).
\end{align} 
Then 
\begin{enumerate}
  \item 
  $\{(V^{(c)}(\tau_n), \tau_{n+1} - \tau_n), n \ge 1\}$ 
  are the points of a bivariate Poisson random measure on
  $(x_l, x_0) \times (0,\infty)$ with mean measure
  \begin{align}
  \mu^*(dx, dy) = R(dx) \PP(T^{(c)}(x) \in dy),
  \end{align}
  \item
  $\{(\tilde V^{(c)}(\tau_n), \tau_{n+1} - \tau_n), n \ge 1\}$ 
  are the points of a bivariate Poisson random measure on
  $(x_l, x_0) \times (0,\infty)$ with mean measure
  \begin{align}
  \mu^*(dx, dy) = R(dx) \PP(W^{(c)}(x) + T^{(c)}(x) \in dy),
  \end{align}
  \item
  $\{(V(\tau_n), \tau_{n+1} - \tau_n), n \ge 1\}$ 
  are the points of a bivariate Poisson random measure on
  $\mathbf U \times (0,\infty)$ with mean measure
  \begin{align}
  \mu^*(dx, dy) = S(dx) \PP(T(x) \in dy),
  \end{align}
  \item
  $\{(\tilde V(\tau_n), \tau_{n+1} - \tau_n), n \ge 1\}$ 
  are the points of a bivariate Poisson random measure on
  $\mathbf U \times (0,\infty)$ with mean measure
  \begin{align}
  \mu^*(dx, dy) = S(dx) \PP(W(x) + T'(x) \in dy).
  \end{align}
\end{enumerate}
\end{theorem}

\begin{proof}
By \cite[Prop 4.1(iii)]{resnick2013extreme} and the observation that 
$V^{(c)}$ and $\tilde V^{(c)}$ are time changes of maximal processes, 
The records $V^{(c)}(\tau_n)$ resp. $\tilde V^{(c)}(\tau_n)$ form 
a PPP with mean measure $R(dx)$. 
Similarly, by \cite[Prop 4.8(iii)]{resnick2013extreme}, the records 
$V(\tau_n)$ and $\tilde V(\tau_n)$ form a PPP with mean measure $S(dx)$. 
By Proposition \ref{prop:semi-markov}, the holding times $\tau_{n+1} - \tau_n$
are conditionally independent given their record 
$V^{(c)}(\tau_n), \tilde V^{(c)}(\tau_n)$, etc.
Applying \cite[Prop 3.8]{resnick2013extreme} to the kernels 
$K(x,dy) = \PP(T^{(c)}(x) \in dy)$, etc., marks each record with its corresponding 
holding time, and proves the theorem. 
\end{proof}




\section{Governing Equations of CTRM limits}




%\section{Conclusion}
\section{Conclusion}


{\bf Acknowledgements.} P. Straka was supported by the Australian Research Councilâ€™s Discovery Early Career Research Award DE160101147.


\bibliographystyle{alpha}
\bibliography{CTRMstats}



\end{document}
